### For-learning-Go-Tutorial

Go语言是谷歌2009发布的第二款开源编程语言。

Go语言专门针对多处理器系统应用程序的编程进行了优化，使用Go编译的程序可以媲美C或C++代码的速度，而且更加安全、支持并行进程。

因而一直想的是自己可以根据自己学习和使用Go语言编程的心得，写一本Go的书可以帮助想要学习Go语言的初学者快速入门开发和使用！

#### TiDB的使用

TiDB 是 PingCAP 公司受 `Google Spanner F1` 论文启发而设计的开源分布式 `HTAP (Hybrid Transactional and Analytical Processing)` 数据库，结合了传统的 RDBMS 和NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 `OLTP(Online Transactional Processing)` 和 `OLAP (Online Analytical Processing)` 场景提供一站式的解决方案。

TiDB支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。TiDB 的设计目标是 100% 的 OLTP 场景和 80% 的 OLAP 场景，更复杂的 OLAP 分析可以通过 TiSpark 项目来完成。 TiDB 对业务没有任何侵入性，能优雅的替换传统的数据库中间件、数据库分库分表等 Sharding 方案。同时它也让开发运维人员不用关注数据库 Scale 的细节问题，专注于业务开发，极大的提升研发的生产力。

在使用TiDB的时候首先要搭建集群，看了下官网有三种部署方法。（Ansible 部署方案），Docker部署方案，Binary部署方案。目前我这里是用了 Docker部署方案和Binary部署方案安装部署的TiDB集群．一个完整的TiDB集群包括 PD，TiKV 以及 TiDB。启动顺序依次是 PD，TiKV 以及 TiDB。

这里有三点需要注意的:

* 快速了解和试用 TiDB，推荐使用单节点方式快速部署。

* 功能性测试 TiDB，推荐使用功能性测试部署。

* 生产环境使用 TiDB，推荐使用多节点集群模式部署。

#### Docker部署方案

首先安装docker环境，这个可以根据电脑系统的不同，选择不同的安装方式。

* [Mac安装](https://docs.docker.com/docker-for-mac/install/)
* [Ubantu安装](https://docs.docker.com/install/linux/docker-ce/ubuntu/)
* [Windows安装](https://docs.docker.com/docker-for-windows/install/)
* [centos安装](https://docs.docker.com/install/linux/docker-ce/centos/)

不过我这里是用脚本直接在centos上直接安装的docker和docker-compose:

```bash
yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo;

yum-config-manager --enable docker-ce-edge;

yum-config-manager --disable docker-ce-edge;

yum install docker-ce;

systemctl start docker.service;
systemctl enable docker.service;

sudo curl -L https://github.com/docker/compose/releases/download/1.16.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose

chmod +x /usr/local/bin/docker-compose;

docker-compose --version;
```

#### 拉取TiDB的Docker镜像

这里需要拉取TiDB的三个镜像,TiDB,TiDB,PD,因为TiDB集群部署主要包括这三个服务组件.

* TiDB Server

TiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。 TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。

* PD Server
Placement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个： 一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。

PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。

* TiKV Server

TiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range （从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region 。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。

然后拉取Docker最新镜像可以通过[Docker官方镜像仓库](https://hub.docker.com/)获取：

```bash
docker pull pingcap/tidb:latest
docker pull pingcap/tikv:latest
docker pull pingcap/pd:latest
```
这里配置5台机器配置如下:

| 组件      | CPU            | 内存            | 实例数量            |
| ---- | ------------------------------- |----------------- |----------------- |
|TiDB| 8核|32 GB|1|
|PD| 8核|32 GB|2|
|TiKV| 8核 |32 GB|3|

然后配置了这样的TiDB集群:

| 主机名      | IP            | 部署服务            | 数据盘挂载            |
| ---- | ------------------------------- |----------------- |----------------- |
|host1| 120.92.150.39|PD1 & TiDB|/data|
|host2| 120.92.163.32|PD2|/data|
|host3| 120.92.172.35 |TiKV1|/data|
|host4| 120.92.169.191|TiKV2|/data|
|host5| 120.92.165.229|TiKV3|/data|

然后需要在host1上配置下免密登录:

```bash
> ssh-keygen -t rsa

>  ls -la .ssh

总用量 16
drwx------  2 usera usera 4096  7月 23 09:22 .
drwxrwx--- 12 usera usera 4096  7月 23 09:22 ..
-rw-------  1 usera usera 1675  7月 23 09:22 id_rsa
-rw-r--r--  1 usera usera  399  7月 23 09:22 id_rsa.pub
```

此时会在/.ssh目录下生成密钥对,然后将公钥上传到其他主机上 服务器的，并以userb用户登录.

```bash
> ssh-copy-id .ssh/id_rsa.pub root@120.92.163.32

> ssh-copy-id .ssh/id_rsa.pub root@120.92.172.35

> ssh-copy-id .ssh/id_rsa.pub root@120.92.169.191

> ssh-copy-id .ssh/id_rsa.pub root@120.92.165.229
```

这样我们就可以使用免密登录了:

```bash
> ssh root@120.92.163.32

> ssh root@120.92.172.35

> ssh root@120.92.169.191

> ssh root@120.92.165.229
```
除此之外也可以用scp命令实现，但是有点麻烦:
```bash
> scp -P 22 ~/.ssh/id_rsa.pub root@120.92.163.32:~/

> scp -P 22 ~/.ssh/id_rsa.pub root@120.92.172.35:~/

> scp -P 22 ~/.ssh/id_rsa.pub root@120.92.169.191:~/

> scp -P 22 ~/.ssh/id_rsa.pub root@120.92.165.229:~/

```
#### 启动PD

登录 host1 执行：
```bash
> docker run -d --name pd1 \
  -p 2379:2379 \
  -p 2380:2380 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /data:/data \
  pingcap/pd:latest \
  --name="pd1" \
  --data-dir="/data/pd1" \
  --client-urls="http://0.0.0.0:2379" \
  --advertise-client-urls="http://120.92.150.39:2379" \
  --peer-urls="http://0.0.0.0:2380" \
  --advertise-peer-urls="http://120.92.150.39:2380" \
  --initial-cluster="pd1=http://120.92.150.39:2380,pd2=http://120.92.163.32:2380"
```

登录 host2 执行：
```bash
> docker run -d --name pd2 \
  -p 2379:2379 \
  -p 2380:2380 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /data:/data \
  pingcap/pd:latest \
  --name="pd2" \
  --data-dir="/data/pd2" \
  --client-urls="http://0.0.0.0:2379" \
  --advertise-client-urls="http://120.92.163.32:2379" \
  --peer-urls="http://0.0.0.0:2380" \
  --advertise-peer-urls="http://120.92.163.32:2380" \
  --initial-cluster="pd1=http://120.92.150.39:2380,pd2=http://120.92.163.32:2380"
```

#### 启动 TiKV

登录 host3 执行：
```bash

> docker run -d --name tikv1 \
 -p 20160:20160 \
 --ulimit nofile=1000000:1000000 \
 -v /etc/localtime:/etc/localtime:ro \
 -v /data:/data \
 pingcap/tikv:latest \
 --addr="0.0.0.0:20160" \
 --advertise-addr="120.92.172.35:20160" \
 --data-dir="/data/tikv1" \
 --pd="120.92.150.39:2379,120.92.163.32:2379"
```


登录 host4 执行：
```bash
> docker run -d --name tikv2 \
  -p 20160:20160 \
  --ulimit nofile=1000000:1000000 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /data:/data \
  pingcap/tikv:latest \
  --addr="0.0.0.0:20160" \
  --advertise-addr="120.92.169.191:20160" \
  --data-dir="/data/tikv2" \
  --pd="120.92.150.39:2379,120.92.163.32:2379"
```

登录 host5 执行：
```bash
> docker run -d --name tikv3\
  -p 20160:20160 \
  --ulimit nofile=1000000:1000000 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /data:/data \
  pingcap/tikv:latest \
  --addr="0.0.0.0:20160" \
  --advertise-addr=" 120.92.165.229:20160" \
  --data-dir="/data/tikv2" \
  --pd="120.92.150.39:2379,120.92.163.32:2379"
```

#### 启动 TiDB

登录 host1 执行：
```bash
docker run -d --name tidb \
  -p 4000:4000 \
  -p 10080:10080 \
  -v /etc/localtime:/etc/localtime:ro \
  pingcap/tidb:latest \
  --store=tikv \
  --path="120.92.150.39:2379,120.92.163.32:2379"
```
登录 host1并确保已安装 MySQL 命令行客户端，执行：
```bash
$ mysql -h 127.0.0.1 -P 4000 -u root -D test
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| INFORMATION_SCHEMA |
| PERFORMANCE_SCHEMA |
| mysql              |
| test               |
+--------------------+
4 rows in set (0.00 sec)
```
#### Binary部署方案

除了上面Docker安装部署，我们也可以用Binary安装和部署TiDB集群．

用Binary部署TiDB需要下载对应的压缩包:

* [tidb-latest-linux-amd64](http://download.pingcap.org/tidb-latest-linux-amd64.tar.gz).

* [tidb-latest-linux-amd64.sha256](http://download.pingcap.org/tidb-latest-linux-amd64.sha256)．

在centos上可以用:
```bash
> wget http://download.pingcap.org/tidb-latest-linux-amd64.targz 

> wget http://download.pingcap.org/tidb-latest-linux-amd64.sha256
```
然后检查文件完整性，返回 ok 则正确．
```bash
> sha256sum -c tidb-latest-linux-amd64.sha256
```
解开压缩包:
```bash
> tar -xzf tidb-latest-linux-amd64.tar.gz cd tidb-latest-linux-amd64
```
我们可以在单机上面，运行和测试 TiDB 集群，请按如下步骤依次启动 PD，TiKV，TiDB.
```bash
#启动 PD
> ./bin/pd-server --data-dir=/data/tidb/pd \
                --log-file=pd.log
#启动 TiKV
> ./bin/tikv-server --pd="127.0.0.1:2379" \
                  --data-dir=/data/tidb/pd \
                  --log-file=tikv.log
#启动 TiDB
> ./bin/tidb-server --store=tikv \
                  --path="127.0.0.1:2379" \
                  --log-file=tidb.log
#使用官方的 mysql 客户端连接 TiDB
> mysql -h 127.0.0.1 -P 4000 -u root -D test

#多节点集群模式部署
```

这里我用了和上面Docker部署一样的５台服务器，２个PD,1个TiDB,和３个TiKV来部署TiDB集群.

| 主机名      | IP            | 部署服务            | 数据盘挂载            |
| ---- | ------------------------------- |----------------- |----------------- |
|host1| 120.92.150.39|PD1 & TiDB|/data|
|host2| 120.92.163.32|PD2|/data|
|host3| 120.92.172.35 |TiKV1|/data|
|host4| 120.92.169.191|TiKV2|/data|
|host5| 120.92.165.229|TiKV3|/data|

```bash
# 在 host1，host2上依次启动 PD:
> ./bin/pd-server --name=pd1 \
                  --data-dir=/data/tidb/pd1 \
                  --client-urls="http://120.92.150.39:2379" \
                  --peer-urls="http://120.92.150.39:2380" \
                  --initial-cluster="pd1=http://120.92.150.39:2380,pd2=http://120.92.163.32:2380"　\
                  --log-file=pd1.log

> ./bin/pd-server --name=pd2 \
                  --data-dir=/data/tidb/pd2 \
                  --client-urls="http://120.92.163.32:2379" \
                  --peer-urls="http://120.92.163.32:2380" \
                  --initial-cluster="pd1=http://120.92.150.39:2380,pd2=http://120.92.163.32:2380"　\
                  --log-file=pd2.log

# 在 host3，host4，host5上启动 TiKV
> ./bin/tikv-server --pd="120.92.150.39:2379,120.92.163.32:2379" \
                    --addr="120.92.172.35:20160" \
                    --data-dir=/data/tidb/tikv1 \
                    --log-file=tikv1.log
                  

> ./bin/tikv-server --pd="120.92.150.39:2379,120.92.163.32:2379" \
                    --addr="120.92.169.191:20160" \
                    --data-dir=/data/tidb/tikv2 \
                    --log-file=tikv2.log
                    
> ./bin/tikv-server --pd="120.92.150.39:2379,120.92.163.32:2379" \
                    --addr="120.92.165.229:20160" \
                    --data-dir=/data/tidb/tikv3 \
                    --log-file=tikv3.log

# 在 host1上启动 TiDB

> ./bin/tidb-server --store=tikv \
                    --path="120.92.150.39:2379" \               
                    --log-file=tidb.log
                    
# 使用官方 mysql 客户端连接 TiDB
> mysql -h 120.92.150.39 -P 4000 -u root -D test
```
注意：在生产环境中启动 TiKV时，建议使用--config参数指定配置文件路径。

如果使用 nohup 在生产环境中启动集群，需要将启动命令放到一个脚本文件里面执行，否则会出现因为 Shell 退出导致 nohup 启动的进程也收到异常信号退出的问题，具体参考进程异常退出。 功能性测试部署．

#### 用sysbench测试TiDB性能

sysbench是一个模块化的、跨平台、多线程基准测试工具，主要用于评估测试各种不同系统参数下的数据库负载情况。

sysbench主要测试方式包括:

* cpu性能
* 磁盘io性能
* 调度程序性能
* 内存分配及传输速度
* POSIX线程性能
* 数据库性能(OLTP基准测试)

sysbench的数据库OLTP测试支持MySQL、PostgreSQL、Oracle，目前主要用于Linux操作系统，开源社区已经将sysbench移植到了Windows，并支持SQL Server的基准测试。

#### sysbench安装

本次安装是在服务器centos7.0上进行的,安装方式主要有两种:

* 可以直接yum -y install sysbench.
```bash
> yum -y install sysbench
> yum -y install automake
> yum -y install libtool
> sysbench --version
sysbench 1.0.9
```

* wget源码编译 wget http://imysql.com/wp-content/uploads/2014/09/sysbench-0.4.12-1.1.tgz.
```bash
> cd /tmp/sysbench-0.4.12-1.1
> ./autogen.sh
> ./configure && make

# 如果make没有报错，就会在sysbench目录下生成二进制命令行工具 sysbench
ls -l sysbench
-rwxr-xr-x 1 root root 3297149 9月 14 sysbench
```
#### 安装TiDB Bench脚本

这里安装的时候需要去[tidb-bench](https://github.com/pingcap/tidb-bench?1531365679915)拉取代码.然后你可以直接上传到服务器上:
```bash
scp tidb-bench-master.zip root@120.92.172.35:~/
```
或者你也可以直接把代码拉取到你要测试的服务器上.

#### 运行测试

接下来就是真正意义上的测试了，这里你需要先使用MySQL标准客户端连接 TiDB
```bash
> mysql -h 120.92.150.39 -P 4000 -u root -D test
> create database sbtest1;
```
然后你就需要用到刚刚获取的beanch的代码了：
```bash
 > cd ~/tidb-bench-master/sysbench
```
修改**conf.sh**:

```bash
> cat conf.sh 
 . ./conf.sh
 host=127.0.0.1
 port=4000
 user=root
 password=
 tcount=16
 tsize=1000000
 threads=256
 dbname=sbtest1
 interval=10
 maxtime=600
 requests=2000000000
 driver=mysql
```
详解：

* --test=tests/db/oltp.lua 表示调用 tests/db/oltp.lua 脚本进行 oltp 模式测试.
* --oltp_tables_count=16 表示会生成16张测试表 .
* --oltp-table-size=500000 表示每张测试表填充数据量为500000 --rand-init=on 表示每张测试表都是用随机数据来填充的.


如果在本机，也可以使用 –mysql-socket 指定 socket 文件来连接。加载测试数据时长视数据量而定，若过程比较久需要稍加耐心等待。 真实测试场景中，数据表建议不低于10个，单表数据量不低于500万行，当然了，要视服务器硬件配置而定。如果是配备了SSD或者PCIE SSD这种高IOPS设备的话，则建议单表数据量最少不低于1亿行。

测试运行:
```bash
> ./prepare.sh
```
执行完成后，生成16张测试表，每张表500000条数据。

开始测试 OLTP，这里解释写关于里面的参数:

* --num-threads=256 表示发起 256 个并发连接. 
* --oltp-read-only=off 表示不要进行只读测试也就是会采用读写混合模式测试.
* --report-interval=10 表示每10秒输出一次测试进度报告.
* --rand-type=uniform 表示随机类型为固定模式，其他几个可选随机模式：uniform(固定),gaussian(高斯),special(特定的),pareto(帕累托). 
* --max-time=600 表示最大执行时长为 600 秒.
* --max-requests=0 表示总请求数为 0，因为上面已经定义了总执行时长，所以总请求数可以设定为 0；也可以只设定总请求数，不设定最大执行时长.
* --percentile=95 表示设定采样比例，默认是 95%，即丢弃5%的长请求，在剩余的95%里取最大值.

模拟 对256个表并发OLTP测试，每个表500000行记录，持续压测时间为10分钟。 真实测试场景中，建议持续压测时长不小于30分钟，否则测试数据可能不具参考意义。

```bash
> ./oltp.sh
+ sysbench --test=./lua-tests/db/oltp.lua --db-driver=mysql --mysql-host=127.0.0.1 --mysql-port=4000 --mysql-user=root --mysql-password= --mysql-db=sbtest1 --oltp-tables-count=16 --oltp-table-size=1000000 --num-threads=256 --max-requests=2000000000 --oltp-read-only=off --report-interval=10 --rand-type=uniform --max-time=600 --percentile=95 run
```
oltp 测试结果如下：
```bash
sysbench 1.0.9 (using system LuaJIT 2.0.4)

Running the test with following options:
Number of threads: 256
Report intermediate results every 10 second(s)
Initializing random number generator from current time

-- 每10秒钟报告一次测试结果，tps、每秒读、每秒写、99%以上的响应时长统计

[ 580s ] thds: 256 tps: 721.70 qps: 14451.55 (r/w/o: 10116.46/2890.59/1444.49) lat (ms,95%): 404.61 err/s: 0.00 reconn/s: 0.00
[ 590s ] thds: 256 tps: 717.67 qps: 14343.25 (r/w/o: 10038.02/2869.89/1435.35) lat (ms,95%): 427.07 err/s: 0.00 reconn/s: 0.00
[ 600s ] thds: 256 tps: 731.61 qps: 14657.79 (r/w/o: 10265.53/2931.24/1461.02) lat (ms,95%): 404.61 err/s: 0.00 reconn/s: 0.00
SQL statistics:
    queries performed:
        read:                            5846120  -- 读总数
        write:                           1670320  -- 写总数
        other:                           835160   -- 其他操作总数(SELECT、INSERT、UPDATE、DELETE之外的操作，例如COMMIT等)
        total:                           8351600  -- 全部总数
    transactions:                        417580 (693.25 per sec.) -- 总事务数(每秒事务数)
    queries:                             8351600 (13864.98 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          602.3476s  -- 总耗时
    total number of events:              417580  -- 共发生多少事务数

Latency (ms):
         min:                                 25.62   -- 最小耗时
         avg:                                367.90   -- 平均耗时
         max:                               5886.23   -- 最长耗时
         95th percentile:                    442.73   
         sum:                            153666263.39

Threads fairness:
    events (avg/stddev):           749.0078/2.01
    execution time (avg/stddev):   600.2588/0.17
```
测试　select:
```bash
> ./select.sh

+ sysbench --test=./lua-tests/db/select.lua --db-driver=mysql --mysql-host=127.0.0.1 --mysql-port=4000 --mysql-user=root --mysql-password= --mysql-db=sbtest1 --oltp-tables-count=16 --oltp-table-size=1000000 --num-threads=256 --report-interval=10 --max-requests=2000000000 --percentile=95 --max-time=600 run
```
select　测试结果如下：
```bash
[ 550s ] thds: 256 tps: 9072.09 qps: 9072.09 (r/w/o: 9072.09/0.00/0.00) lat (ms,95%): 51.94 err/s: 0.00 reconn/s: 0.00
[ 560s ] thds: 256 tps: 7348.60 qps: 7348.60 (r/w/o: 7348.60/0.00/0.00) lat (ms,95%): 69.29 err/s: 0.00 reconn/s: 0.00
[ 570s ] thds: 256 tps: 7644.35 qps: 7644.35 (r/w/o: 7644.35/0.00/0.00) lat (ms,95%): 63.32 err/s: 0.00 reconn/s: 0.00
[ 580s ] thds: 256 tps: 7989.24 qps: 7989.24 (r/w/o: 7989.24/0.00/0.00) lat (ms,95%): 61.08 err/s: 0.00 reconn/s: 0.00
[ 590s ] thds: 256 tps: 8266.79 qps: 8266.79 (r/w/o: 8266.79/0.00/0.00) lat (ms,95%): 58.92 err/s: 0.00 reconn/s: 0.00
[ 600s ] thds: 256 tps: 8126.22 qps: 8126.22 (r/w/o: 8126.22/0.00/0.00) lat (ms,95%): 61.08 err/s: 0.00 reconn/s: 0.00
SQL statistics:
    queries performed:
        read:                            5071951
        write:                           0
        other:                           0
        total:                           5071951
    transactions:                        5071951 (8451.70 per sec.)
    queries:                             5071951 (8451.70 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          600.1084s
    total number of events:              5071951

Latency (ms):
         min:                                  2.87
         avg:                                 30.28
         max:                                369.50
         95th percentile:                     55.82
         sum:                            153576184.73

Threads fairness:
    events (avg/stddev):           19812.3086/50.79
    execution time (avg/stddev):   599.9070/0.04

```
测试　insert：

```bash
> ./insert.sh

+ sysbench --test=./lua-tests/db/insert.lua --db-driver=mysql --mysql-host=127.0.0.1 --mysql-port=4000 --mysql-user=root --mysql-password= --mysql-db=sbtest1 --oltp-tables-count=16 --oltp-table-size=1000000 --num-threads=256 --report-interval=10 --max-requests=2000000000 --percentile=95 --max-time=600 run
```
insert　测试结果如下：
```bash
[ 550s ] thds: 256 tps: 3084.73 qps: 3084.73 (r/w/o: 0.00/3084.73/0.00) lat (ms,95%): 110.66 err/s: 0.00 reconn/s: 0.00
[ 560s ] thds: 256 tps: 3164.70 qps: 3164.70 (r/w/o: 0.00/3164.70/0.00) lat (ms,95%): 104.84 err/s: 0.00 reconn/s: 0.00
[ 570s ] thds: 256 tps: 3118.42 qps: 3118.42 (r/w/o: 0.00/3118.42/0.00) lat (ms,95%): 108.68 err/s: 0.00 reconn/s: 0.00
[ 580s ] thds: 256 tps: 3251.01 qps: 3251.01 (r/w/o: 0.00/3251.01/0.00) lat (ms,95%): 101.13 err/s: 0.00 reconn/s: 0.00
[ 590s ] thds: 256 tps: 3109.42 qps: 3109.42 (r/w/o: 0.00/3109.42/0.00) lat (ms,95%): 106.75 err/s: 0.00 reconn/s: 0.00
SQL statistics:
    queries performed:
        read:                            0
        write:                           1765555
        other:                           0
        total:                           1765555
    transactions:                        1765555 (2942.26 per sec.)
    queries:                             1765555 (2942.26 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          600.0653s
    total number of events:              1765555

Latency (ms):
         min:                                 34.19
         avg:                                 86.99
         max:                                927.90
         95th percentile:                    114.72
         sum:                            153582581.05

Threads fairness:
    events (avg/stddev):           6896.6992/13.22
    execution time (avg/stddev):   599.9320/0.05
```
测试 delete:
```bash
> ./delete.sh

+  sysbench --test=./lua-tests/db/delete.lua --db-driver=mysql --mysql-host=127.0.0.1 --mysql-port=4000 --mysql-user=root --mysql-password= --mysql-db=sbtest1 --oltp-tables-count=16 --oltp-table-size=1000000 --num-threads=256 --report-interval=10 --max-requests=2000000000 --max-time=600 --percentile=95 run
```
delete　测试结果如下：

```bash
[ 550s ] thds: 256 tps: 6291.62 qps: 6291.62 (r/w/o: 0.00/1284.15/5007.48) lat (ms,95%): 99.33 err/s: 0.00 reconn/s: 0.00
[ 560s ] thds: 256 tps: 6294.83 qps: 6294.83 (r/w/o: 0.00/1278.81/5016.02) lat (ms,95%): 99.33 err/s: 0.00 reconn/s: 0.00
[ 570s ] thds: 256 tps: 6161.33 qps: 6161.33 (r/w/o: 0.00/1252.58/4908.75) lat (ms,95%): 97.55 err/s: 0.00 reconn/s: 0.00
[ 580s ] thds: 256 tps: 6190.38 qps: 6190.48 (r/w/o: 0.00/1244.62/4945.86) lat (ms,95%): 97.55 err/s: 0.00 reconn/s: 0.00
[ 590s ] thds: 256 tps: 6278.86 qps: 6278.76 (r/w/o: 0.00/1279.15/4999.61) lat (ms,95%): 99.33 err/s: 0.00 reconn/s: 0.00
SQL statistics:
    queries performed:
        read:                            0
        write:                           887497
        other:                           2589396
        total:                           3476893
    transactions:                        3476893 (5793.68 per sec.)
    queries:                             3476893 (5793.68 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          600.1166s
    total number of events:              3476893

Latency (ms):
         min:                                  5.06
         avg:                                 44.17
         max:                               5644.54
         95th percentile:                    102.97
         sum:                            153575902.59

Threads fairness:
    events (avg/stddev):           13581.6133/78.13
    execution time (avg/stddev):   599.9059/0.05
```

